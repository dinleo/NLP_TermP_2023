{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bNbJxCf47tks",
    "outputId": "e811495e-187e-45ed-b44a-f122e78e5aca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: mxnet==1.6.0 in /home/minhyuk/.local/lib/python3.8/site-packages (1.6.0)\n",
      "Requirement already satisfied: numpy==1.23.1 in /home/minhyuk/.local/lib/python3.8/site-packages (1.23.1)\n",
      "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /home/minhyuk/.local/lib/python3.8/site-packages (from mxnet==1.6.0) (0.8.4)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /home/injae/.conda/envs/nips23/lib/python3.8/site-packages (from mxnet==1.6.0) (2.29.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/injae/.conda/envs/nips23/lib/python3.8/site-packages (from requests<3,>=2.20.0->mxnet==1.6.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/minhyuk/.local/lib/python3.8/site-packages (from requests<3,>=2.20.0->mxnet==1.6.0) (1.25.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/injae/.conda/envs/nips23/lib/python3.8/site-packages (from requests<3,>=2.20.0->mxnet==1.6.0) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/injae/.conda/envs/nips23/lib/python3.8/site-packages (from requests<3,>=2.20.0->mxnet==1.6.0) (2022.12.7)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gluonnlp==0.8.0 in /home/minhyuk/.local/lib/python3.8/site-packages (0.8.0)\n",
      "Requirement already satisfied: numpy in /home/minhyuk/.local/lib/python3.8/site-packages (from gluonnlp==0.8.0) (1.23.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tqdm in /home/injae/.conda/envs/nips23/lib/python3.8/site-packages (4.65.0)\n",
      "Requirement already satisfied: pandas in /home/injae/.conda/envs/nips23/lib/python3.8/site-packages (2.0.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/injae/.conda/envs/nips23/lib/python3.8/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/injae/.conda/envs/nips23/lib/python3.8/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/injae/.conda/envs/nips23/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /home/minhyuk/.local/lib/python3.8/site-packages (from pandas) (1.23.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/injae/.conda/envs/nips23/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentencepiece in /home/minhyuk/.local/lib/python3.8/site-packages (0.1.96)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/minhyuk/.local/lib/python3.8/site-packages (4.8.1)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /home/minhyuk/.local/lib/python3.8/site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: packaging in /home/injae/.conda/envs/nips23/lib/python3.8/site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/minhyuk/.local/lib/python3.8/site-packages (from transformers) (1.23.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/injae/.conda/envs/nips23/lib/python3.8/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: requests in /home/injae/.conda/envs/nips23/lib/python3.8/site-packages (from transformers) (2.29.0)\n",
      "Requirement already satisfied: sacremoses in /home/minhyuk/.local/lib/python3.8/site-packages (from transformers) (0.0.53)\n",
      "Requirement already satisfied: filelock in /home/injae/.conda/envs/nips23/lib/python3.8/site-packages (from transformers) (3.12.0)\n",
      "Requirement already satisfied: pyyaml in /home/injae/.conda/envs/nips23/lib/python3.8/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/minhyuk/.local/lib/python3.8/site-packages (from transformers) (2023.5.5)\n",
      "Requirement already satisfied: huggingface-hub==0.0.12 in /home/minhyuk/.local/lib/python3.8/site-packages (from transformers) (0.0.12)\n",
      "Requirement already satisfied: typing-extensions in /home/injae/.conda/envs/nips23/lib/python3.8/site-packages (from huggingface-hub==0.0.12->transformers) (4.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/injae/.conda/envs/nips23/lib/python3.8/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/injae/.conda/envs/nips23/lib/python3.8/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/minhyuk/.local/lib/python3.8/site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/injae/.conda/envs/nips23/lib/python3.8/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: six in /home/injae/.conda/envs/nips23/lib/python3.8/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: click in /home/injae/.conda/envs/nips23/lib/python3.8/site-packages (from sacremoses->transformers) (8.1.3)\n",
      "Requirement already satisfied: joblib in /home/injae/.conda/envs/nips23/lib/python3.8/site-packages (from sacremoses->transformers) (1.2.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /home/injae/.conda/envs/nips23/lib/python3.8/site-packages (1.11.0)\n",
      "Requirement already satisfied: typing_extensions in /home/injae/.conda/envs/nips23/lib/python3.8/site-packages (from torch) (4.5.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting kobert_tokenizer\n",
      "  Cloning https://github.com/SKTBrain/KoBERT.git to /tmp/pip-install-puqcwcac/kobert-tokenizer_ef2ab81ca6344ed98a8b55a5720349d8\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/SKTBrain/KoBERT.git /tmp/pip-install-puqcwcac/kobert-tokenizer_ef2ab81ca6344ed98a8b55a5720349d8\n",
      "  Resolved https://github.com/SKTBrain/KoBERT.git to commit 47a69af87928fc24e20f571fe10c3cc9dd9af9a3\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\n",
      "\u001B[?25hDefaulting to user installation because normal site-packages is not writeable\n"
     ]
    }
   ],
   "source": [
    "!pip install mxnet==1.6.0 numpy==1.23.1\n",
    "!pip install gluonnlp==0.8.0\n",
    "!pip install tqdm pandas\n",
    "!pip install sentencepiece\n",
    "!pip install transformers\n",
    "!pip install torch\n",
    "!pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'\n",
    "!pip install pytorch-transformers\n",
    "!pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SqcGbumW8YiL",
    "outputId": "9dbbab16-c4d5-4a45-9b66-fafad8cc7896"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minhyuk/.local/lib/python3.8/site-packages/mxnet/optimizer/optimizer.py:163: UserWarning: WARNING: New optimizer gluonnlp.optimizer.lamb.LAMB is overriding existing optimizer mxnet.optimizer.optimizer.LAMB\n",
      "  warnings.warn('WARNING: New optimizer %s.%s is overriding '\n",
      "[nltk_data] Downloading package punkt to /home/minhyuk/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device('cpu')\n",
    "EMBED_SIZE = 768\n",
    "NUM_HEADS = 8\n",
    "MAX_LEN = 256\n",
    "BATCH = 8\n",
    "LR_RATE=1e-4\n",
    "EPOCHS = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ifYT1s0B8Yke"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The Ethereum Name Service (ENS), a protocol that sells nonfungible tokens (NFTs) of domains representing wallet addresses, generated buzz within the crypto community in November after it airdropped tokens to its users. Those who claimed the tokens earned governance rights over the ENS and can vote on future decisions regarding the protocol.It was so well received that it prompted other Ethereum projects to airdrop tokens too. Though airdrops aren\\'t new, they\\'ve recently become increasingly common.In an airdrop, projects distribute tokens to specific investors\\' wallets. In some situations, like with the ENS, projects airdrop tokens to those who have used their product. Other times, projects airdrop tokens to potential investors in hopes of marketing their product.The process of receiving the airdropped tokens can differ too. Sometimes, investors must choose to accept the tokens by claiming them, while other times, investors cannot reject the airdrop and tokens are automatically dropped in their wallets.The ENS airdrop seems legitimate, as the ENS has existed for years and it required investors to vote on a \"foundational ENS governance constitution\" that detailed the authority of holders before claiming their tokens. But airdrops are often used by crypto scammers. In some cases, they may try to\\xa0airdrop fictitious tokens to an investor\\'s wallet\\xa0to prompt them to visit a phishing website.It can be difficult to tell whether an airdrop is safe or not, and investors should be cautious. Before claiming airdropped tokens or interacting with any that may have landed in your wallet, there are a few things to do first. If you have the option to claim airdropped tokens, you should first\\xa0look into the project distributing and see whether it has a viable product.Even if the airdropped token is safe to claim, its project may be designed to benefit a select few founders or core contributors. Details about a drop and its project can be found in its code, on its website or via its social media. Look into a project\\'s fundamentals and what it proposes before connecting your wallet to its website.Both the OpenDAO and Gas DAO, two Ethereum-based projects, recently airdropped tokens, which quickly surged in value before declining. While the airdrops garnered excitement from some, others expressed concern, saying the projects behind the tokens lacked product development, utility and had security risks. This isn\\'t uncommon.If tokens land in your wallet through an airdrop you didn\\'t initiate, it\\'s best to wait before engaging. Some airdrops may prompt you to visit a website to sell or swap the tokens, but there\\'s a possibility it\\'s a phishing attempt to access your wallet and funds. When researching, there are a few common red flags to be aware of, many of which can be seen when analyzing a project\\'s smart contract, which are collections of code that carry out a set of instructions on the blockchain.For one, if a project lacks on-chain security to protect funds, its founders or developers might be able to control the movement of funds. This commonly happens in \"pump and dump\"\\xa0or\\xa0\"rug pull\" schemes,\\xa0where developers abandon a project and leave with investors\\' funds.In addition, it might be a bad sign if a project airdropping tokens doesn\\'t have a product, plan, governance outline or other things of that nature. Claiming tokens now with the promise of being told details later can be dangerous. While this can sometimes also be the case for early crypto projects, where there isn\\'t any malice, it\\'s worth keeping in mind.Project founders should be somewhat receptive to answering questions on Discord or Twitter, especially if people are calling out potential issues or concerns. If they aren\\'t, that can be a red flag as well.Another is if a project charges a fee when you try to swap or sell the tokens, or simply doesn\\'t allow you to swap or sell at all. Smart contracts are essential for most crypto-based projects to run. Although they can be quite technical, it\\'s worth checking out the smart contract behind a project, or asking someone knowledgeable about the space to do so. If there is an issue with a developer\\'s code, intentionally or not, then there could potentially be weaknesses within the project.Sign up now: Get smarter about your money and career with our weekly newsletterDon\\'t miss:You could be leaving your crypto wallet open to hackers—here\\'s how to protect it\\'People have been participating without understanding the risks\\': Here\\'s what to know about cryptocurrency-based DeFiElon Musk continues to tweet about altcoins like baby dogecoin—but investors should tread very carefully', 'China\\'s central bank has launched a pilot version of a wallet app for the digital yuan in a push to expand its usage to more people.So far, China has done a number of trials around the country in the form of lotteries where users in certain cities have been given a small amount of the digital currency to spend.But now more people in certain cities can download the app, highlighting how China is trying to get more people to use the digital currency. China\\'s central bank has launched a pilot version of a wallet app for the digital yuan in a push to expand its usage to more people.The app is available on China\\'s Android app stores and Apple\\'s app store. It allows users to open a digital yuan wallet and spend the currency.The digital yuan or e-CNY is a digital version of China\\'s sovereign currency and has been in the works since 2014. It is not a cryptocurrency like bitcoin but is instead issued and controlled by the People\\'s Bank of China.So far, China has done a number of trials around the country in the form of lotteries where users in certain cities have been given a small amount of digital currency to spend. Some retailers, such as e-commerce company JD.com, have accepted it as payment in the past year.But the digital yuan has not yet officially been rolled out nationally and there is no timeline for this.The new app allows users in 10 areas including major cities Shanghai and Beijing to use it. Previously, only select users could use the app on an invitation basis. But now everyone can download the app, highlighting how China is trying to get more people to use the digital currency. The \"Beijing Winter Olympics areas\" is one of the places that the digital yuan can be used, according to a notice on the app. The Winter Olympics, which takes place this year in the Chinese capital, has been one of the events that the People\\'s Bank of China has been targeting bringing the digital yuan to.Still, the e-CNY app will face stiff competition from China\\'s two dominant digital payment apps — Ant Group\\'s Alipay and Tencent\\'s WeChat.', 'Bitcoin could see further upside and reach $100,000 by the middle of this year, claims Antoni Trenchev of crypto lender Nexo.Bitcoin has been a winner in the pandemic era, rising more than 80% in 2021 despite being far off record highs hit earlier that year.However, some experts have warned that bitcoin may be poised for a steep drop in the coming months. Bitcoin could see further upside and surge as high as $100,000 by the middle of 2022, according to Antoni Trenchev of cryptocurrency lender Nexo.The world\\'s largest cryptocurrency by market cap was trading at $46,170.43 as of 8:42 p.m. ET Monday, according to data from Coin Metrics.\"I\\xa0think [bitcoin\\'s] going to reach $100,000 this year, probably by … the middle of it,\" Trenchev, co-founder and managing partner at Nexo, told CNBC\\'s \"Street Signs Asia\" on Monday. The firm claims to be the world\\'s largest lending institution in the digital finance industry, according to its website. The company has issued more than $6 billion in credit and manages assets for more than 2.5 million users globally, it said.Bitcoin has largely been a winner in the pandemic era, rising more than 60% in 2021 despite being far off its record high of around $69,000 earlier that year. In comparison, the S&P 500 rose nearly 27% during the same period, while the Dow and Nasdaq gained 18.73% and 21.39% for the year, respectively.But not everyone is as bullish as Trenchev.Some experts have warned that bitcoin may be poised for a steep drop in the coming months. Carol Alexander, professor of finance at Sussex University, said she sees bitcoin tanking as low as $10,000 in 2022, virtually wiping out all of its gains in the past year and a half. Lingering regulatory scrutiny on the sector and wild price swings could also weigh on the outlook for bitcoin.On his part, Trenchev said there were \"two simple reasons\" why he sees big gains ahead for bitcoin.One is that institutions are \"building out their treasuries\" and filling it with the cryptocurrency, he said, without providing any examples. Firms such as MicroStrategy and Square are among known examples of companies that have bought massive amounts of bitcoin.Another reason is his prediction that \"cheap money\" is here to stay — which will be a boon for cryptocurrencies. Read more about tech and crypto from CNBC ProGoldman Sachs loves Uber, Meta and Amazon — and ranks them in order of preferenceBroadcom bolsters stock with new Apple deal. Here\\'s why the experts like itHere are Cowen\\'s top chip picks for an EV and autonomous-auto future Goldman Sachs loves Uber, Meta and Amazon — and ranks them in order of preferenceBroadcom bolsters stock with new Apple deal. Here\\'s why the experts like itHere are Cowen\\'s top chip picks for an EV and autonomous-auto future His comments come despite expectations the Federal Reserve could raise interest rates several times this year for the first time in the pandemic era as the U.S. central bank seeks to combat inflation. The Fed was among major central banks that took unprecedented monetary easing steps in 2020 to keep financial markets afloat during the early days of the pandemic.Admitting his \"contrarian\" view of lasting easy monetary policy, Trenchev said most people likely \"got it wrong\" in their Fed rate hike expectations.\"I quite frankly think that as soon as we see a rate hike, it\\'s going to be a dip into equities and the bond market — and quite frankly, the last few years, we haven\\'t seen much political will to … power through any sort of correction in the traditional financial markets,\" he said.— CNBC\\'s Ryan Browne contributed to this report.']\n",
      "{'2022-01-03': 0, '2022-01-04': 0, '2022-01-05': 0, '2022-01-06': 0, '2022-01-07': 0, '2022-01-10': 0, '2022-01-11': 0, '2022-01-12': 0, '2022-01-13': 0, '2022-01-14': 0, '2022-01-17': 0, '2022-01-18': 0, '2022-01-19': 0, '2022-01-20': 0, '2022-01-21': 1, '2022-01-24': 1, '2022-01-25': 1, '2022-01-26': 1, '2022-01-27': 1, '2022-01-28': 1, '2022-01-31': 1, '2022-02-01': 1, '2022-02-02': 1, '2022-02-03': 1, '2022-02-04': 1, '2022-02-07': 0, '2022-02-08': 0, '2022-02-09': 0, '2022-02-10': 0, '2022-02-11': 0, '2022-02-14': 1, '2022-02-15': 0, '2022-02-16': 0, '2022-02-17': 1, '2022-02-18': 1, '2022-02-21': 1, '2022-02-22': 1, '2022-02-23': 1, '2022-02-24': 1, '2022-02-25': 1, '2022-02-28': 0, '2022-03-01': 0, '2022-03-02': 0, '2022-03-03': 0, '2022-03-04': 0, '2022-03-07': 1, '2022-03-08': 1, '2022-03-09': 0, '2022-03-10': 1, '2022-03-11': 1, '2022-03-14': 1, '2022-03-15': 1, '2022-03-16': 1, '2022-03-17': 1, '2022-03-18': 1, '2022-03-21': 1, '2022-03-22': 1, '2022-03-23': 1, '2022-03-24': 0, '2022-03-25': 1, '2022-03-28': 0, '2022-03-29': 0, '2022-03-30': 0, '2022-03-31': 0, '2022-04-01': 0, '2022-04-04': 0, '2022-04-05': 0, '2022-04-06': 0, '2022-04-07': 0, '2022-04-08': 0, '2022-04-11': 0, '2022-04-12': 0, '2022-04-13': 0, '2022-04-14': 0, '2022-04-15': 0, '2022-04-18': 0, '2022-04-19': 0, '2022-04-20': 0, '2022-04-21': 0, '2022-04-22': 0, '2022-04-25': 0, '2022-04-26': 0, '2022-04-27': 0, '2022-04-28': 0, '2022-04-29': 0, '2022-05-02': 0, '2022-05-03': 0, '2022-05-04': 0, '2022-05-05': 0, '2022-05-06': 0, '2022-05-09': 0, '2022-05-10': 0, '2022-05-11': 0, '2022-05-12': 0, '2022-05-13': 0, '2022-05-16': 0, '2022-05-17': 0, '2022-05-18': 0, '2022-05-19': 0, '2022-05-20': 0, '2022-05-23': 0, '2022-05-24': 0, '2022-05-25': 0, '2022-05-26': 0, '2022-05-27': 1, '2022-05-30': 0, '2022-05-31': 0, '2022-06-01': 0, '2022-06-02': 0, '2022-06-03': 0, '2022-06-06': 0, '2022-06-07': 0, '2022-06-08': 0, '2022-06-09': 0, '2022-06-10': 0, '2022-06-13': 0, '2022-06-14': 1, '2022-06-15': 0, '2022-06-16': 1, '2022-06-17': 1, '2022-06-20': 1, '2022-06-21': 1, '2022-06-22': 1, '2022-06-23': 1, '2022-06-24': 1, '2022-06-27': 1, '2022-06-28': 1, '2022-06-29': 1, '2022-06-30': 1, '2022-07-01': 1, '2022-07-04': 1, '2022-07-05': 1, '2022-07-06': 1, '2022-07-07': 1, '2022-07-08': 1, '2022-07-11': 1, '2022-07-12': 1, '2022-07-13': 1, '2022-07-14': 1, '2022-07-15': 1, '2022-07-18': 1, '2022-07-19': 0, '2022-07-20': 1, '2022-07-21': 0, '2022-07-22': 0, '2022-07-25': 1, '2022-07-26': 1, '2022-07-27': 1, '2022-07-28': 0, '2022-07-29': 0, '2022-08-01': 1, '2022-08-02': 1, '2022-08-03': 1, '2022-08-04': 1, '2022-08-05': 0, '2022-08-08': 0, '2022-08-09': 0, '2022-08-10': 0, '2022-08-11': 0, '2022-08-12': 0, '2022-08-15': 0, '2022-08-16': 0, '2022-08-17': 0, '2022-08-18': 0, '2022-08-19': 0, '2022-08-22': 0, '2022-08-23': 0, '2022-08-24': 0, '2022-08-25': 0, '2022-08-26': 0, '2022-08-29': 0, '2022-08-30': 0, '2022-08-31': 1, '2022-09-01': 1, '2022-09-02': 0, '2022-09-05': 0, '2022-09-06': 1, '2022-09-07': 0, '2022-09-08': 1, '2022-09-09': 0, '2022-09-12': 0, '2022-09-13': 0, '2022-09-14': 0, '2022-09-15': 0, '2022-09-16': 0, '2022-09-19': 1, '2022-09-20': 1, '2022-09-21': 1, '2022-09-22': 1, '2022-09-23': 1, '2022-09-26': 1, '2022-09-27': 1, '2022-09-28': 0, '2022-09-29': 0, '2022-09-30': 0, '2022-10-03': 0, '2022-10-04': 0, '2022-10-05': 0, '2022-10-06': 0, '2022-10-07': 0, '2022-10-10': 0, '2022-10-11': 0, '2022-10-12': 0, '2022-10-13': 0, '2022-10-14': 1, '2022-10-17': 0, '2022-10-18': 0, '2022-10-19': 1, '2022-10-20': 1, '2022-10-21': 1, '2022-10-24': 1, '2022-10-25': 0, '2022-10-26': 0, '2022-10-27': 0, '2022-10-28': 0, '2022-10-31': 0, '2022-11-01': 0, '2022-11-02': 0, '2022-11-03': 0, '2022-11-04': 0, '2022-11-07': 0, '2022-11-08': 0, '2022-11-09': 1, '2022-11-10': 0, '2022-11-11': 0, '2022-11-14': 0, '2022-11-15': 0, '2022-11-16': 0, '2022-11-17': 0, '2022-11-18': 0, '2022-11-21': 1, '2022-11-22': 1, '2022-11-23': 1, '2022-11-24': 1, '2022-11-25': 0, '2022-11-28': 1, '2022-11-29': 1, '2022-11-30': 0, '2022-12-01': 1, '2022-12-02': 1, '2022-12-05': 1, '2022-12-06': 1, '2022-12-07': 1, '2022-12-08': 1, '2022-12-09': 1, '2022-12-12': 1, '2022-12-13': 1, '2022-12-14': 1, '2022-12-15': 1, '2022-12-16': 1, '2022-12-19': 1, '2022-12-20': 1, '2022-12-21': 1, '2022-12-22': 1, '2022-12-23': 1, '2022-12-26': 1, '2022-12-27': 1, '2022-12-28': 1, '2022-12-29': 1, '2022-12-30': 1}\n"
     ]
    }
   ],
   "source": [
    "news_dict = dict()\n",
    "for row in pd.read_csv('data/news/news_body/crypto_news_body.csv').itertuples():\n",
    "    if type(row.body) is not str: # nan\n",
    "        continue\n",
    "    if row.time in news_dict:\n",
    "        news_dict[row.time].append(row.body)\n",
    "    else:\n",
    "        news_dict[row.time] = [row.body]\n",
    "print(news_dict['2022-01-04'])\n",
    "\n",
    "label_dict = dict() # default value is zero\n",
    "for row in pd.read_csv('data/marketCap/label/labeled_CRYPTO.csv').itertuples():\n",
    "    if row.score > 0:\n",
    "        label_dict[row.time] = 1\n",
    "    else:\n",
    "        label_dict[row.time] = 0\n",
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CoinFlex said it would issue $47 million of a digital coin it is calling Recovery Value USD, or rvUSD.CoinFlex CEO Mark Lamb said in a blogpost that a long-time customer\\'s account went into \"negative equity.\" That prompted the company to halt withdrawals.By issuing the new rvUSD tokens, CoinFlex will be hoping to raise enough money to cover the shortfall in its books left by the investor and resume withdrawals for users. Cryptocurrency exchange CoinFlex on Tuesday issued a new token to raise funds in a bid to restart withdrawals for its customers, after one client failed to repay a massive debt.CoinFlex said it would issue $47 million worth of a digital coin, offering 20% interest, which it\\'s calling Recovery Value USD, or rvUSD.It comes after the company paused withdrawals for customers last week citing \"extreme market conditions\" and \"uncertainty involving a counterparty.\"On Monday, CoinFlex published a blogpost with more details about the counterparty. CEO Mark Lamb said in the post that a long-time customer\\'s account went into \"negative equity.\" That prompted the company to halt withdrawals.CoinFlex said in normal circumstances it would automatically liquidate the investor\\'s position but the trader had a clause in his account that did not allow that to happen. That condition required the individual to \"pledge stringent personal guarantees around account equity and margin calls in exchange for not being liquidated,\" CoinFlex said.The company declined to name the investor, but said the individual \"is a high-integrity person of significant means, experiencing temporary liquidity issues due to a credit (and price) crunch in crypto markets (and non-crypto markets), with substantial shareholdings in several unicorn private companies and a large portfolio.\" By issuing the new rvUSD tokens, CoinFlex will be hoping to raise enough money to cover the shortfall in its books left by the investor and resume withdrawals for users. It is offering a 20% interest rate for people willing to buy rvUSD to entice investors.\"We have been speaking to potential large buyers and believe there is significant interest in the terms presented,\" Lamb said.But part of CoinFlex\\'s plan is hoping that it gets repaid by the investor, which of course, may not happen. Lamb told Bloomberg on Monday that he believes the investor will repay the company \"at some point in the future.\"He added that the company has \"alternative mechanisms\" if it can\\'t raise money from issuing rvUSD, but did not elaborate on what those would be.CoinFlex said it hopes to resume withdrawals on June 30. If the rvUSD token issuance is fully subscribed, CoinFlex will re-enable withdrawals and restore the platform to full functionality, the company said.Many users were angry at Lamb. In the company\\'s official Telegram channel, users questioned why CoinFlex was not naming the investor, criticized the company\\'s risk management strategy and also asked how the firm could offer a 20% yield on its new coin.Lamb did not respond to a request for comment when contacted by CNBC via Telegram. CoinFlex is the latest victim of a massive drop in cryptocurrency prices in the last few weeks which has wiped billions of dollars off of the digital coin market.The new so-called \"crypto winter\" has exposed the weaknesses in a number of companies\\' business models that rely heavily on lending and highly-leveraged trading strategies.Celsius, a crypto lending platform that promised high yields to users who deposited their cryptocurrency, paused withdrawals earlier this month. On Monday, high-profile crypto hedge fund Three Arrows Capital defaulted on a loan worth more than $670 million from Voyager Digital.CoinFlex\\'s Lamb promised more transparency in Monday\\'s blogpost. He said that the value of every account\\'s futures position will be made publicly available via an external audit firm that will attest to these positions every hour. The company will also give information on the collateral backing these trading positions. The data will be anonymized however, CoinFlex said.Lamb said this data would give users insight into \"how risky the platform is, how leveraged the users are, and whether any liquidations occur at a loss to the platform.\"', 'Bitfury Group CEO Brian Brooks, who previously headed the federal government\\'s Office of the Comptroller of the Currency, said crypto valuations should not be tied to the idea they can replace the U.S. dollar, during a discussion at the Aspen Ideas Festival.Rather, Brooks said, cryptocurrencies should be viewed as replacing the system of transmitting value.Despite the recent failure of stablecoin TerraUSD, Brooks said he was bullish on the concept of stablecoins playing a bigger role in the banking system in the future. Crypto prices should be viewed more like internet stocks than currency, said Brian Brooks, the former U.S. Acting Comptroller of the Currency during the Trump Administration.The biggest misunderstanding around cryptocurrencies is that if they\\'re \"not doing a great job of replacing the U.S. dollar, then crypto is failing in its mission,\" Brooks, now the CEO of bitcoin mining and crypto tech company Bitfury Group, told CNBC\\'s Ylan Muii at the Aspen Ideas Festival on Monday.\"Most of crypto is about replacing the centralized banking system with networks that allow user control versus bank control ... the crypto assets that have prices are more like internet stocks,\" Brooks said. \"It\\'s more like you bet on Google if you think there\\'s going to be high internet traffic; if you short it, it\\'s that people are going to go back to the post office, right? But it\\'s not that ethereum or Ripple or anything else is trying to replace the U.S. dollar, it\\'s trying to replace the system of transmitting value,\" he said.The entire crypto market has slumped in 2022, leading to fears of another \"crypto winter.\" Several crypto and tech companies have quickly reversed hiring plans, while many, including leading exchange Coinbase, have laid off workers amid the slide in crypto prices and trading.It has also led many in the industry to forecast that potentially thousands of digital tokens could collapse, a concern that only grew following the recent\\xa0collapse of so-called algorithmic stablecoin terraUSD\\xa0and its associated digital token luna. There are more than 19,000 cryptocurrencies in existence and dozens of blockchain platforms that exist, according to CNBC research.The Terra issue showed \"we\\'re at the stage where basically there are far too many blockchains out there, too many tokens. And that\\'s confusing users. And that\\'s also bringing some risks for the users,\" Bertrand Perez, CEO of the Web3 Foundation, told CNBC at the World Economic Forum in Davos last month. \"Like at the beginning of the internet, you were having lots of dotcom companies and lots of them were scams, and were not bringing any value and all that got cleared. And now we have very useful and legit companies,\" Perez said.Brooks said that it is worth noting that even amid the crash in prices, bitcoin has still outperformed the S&P 500 by 5x in the last 12 months, and that there isn\\'t a session about \"the future of U.S. equities\" at the Aspen Ideas Festival. Bitcoin is down more than 56% year-to-date.But even amid those sharp changes in valuation, the pricing of cryptocurrencies is \"not that relevant any more than Google\\'s volatility,\" he said.\"The value of these tokens you\\'re getting is related to the adoption rate of the underlying [technology], that tens of millions of people are transacting bitcoin, the value of bitcoin goes way up,\" he said. \"That is why bitcoin isn\\'t going to stay at $20,000 because more and more people use it. Same with a lot of other things,\" Brooks said. \"The value of the network is what drives the value of the token,\" he added.Brooks, who signed the first regulatory guidance that defined what a stablecoin was and how it would be allowed inside the U.S. banking system, said that \"stablecoins will become what people think of bank deposits today.\"\"These will be bank deposits that don\\'t have a minimum balance fee, don\\'t have a monthly maintenance fee, don\\'t have a transaction fee,\" Brooks said, noting that he thinks stablecoins will have a significant impact for lower-income Americans as a result.Disclosure: NBCUniversal News Group is the media partner of the Aspen Ideas Festival.', 'Perhaps the most prominent celebrity figure in the Web3 zeitgeist is Snoop Dogg, along with his son Cordell Broadus, a.k.a. Champ Medici.\"I feel like this [crypto winter] weeded out all the people who weren\\'t supposed to be in the space and who were abusing the opportunities that were there,\" Snoop told CNBC in an exclusive interview at last week\\'s NFT.NYC conference in New York City.A liquidity crunch has\\xa0pushed major crypto players into financial difficulty and given a megaphone to some of the biggest NFT skeptics. Perhaps the most prominent celebrity figure in the Web3 zeitgeist is Snoop Dogg, but for Snoop being an early adopter is nothing new. In 2014, the rap icon was part of a $50 million investment into Reddit, which valued the company at around $500 million at the time. Today, the platform is worth $15 billion, according to PitchBook data. He\\'s also known for private investments into fintech companies like Robinhood, Klarna and MoonPay, and for investments in the cannabis space. In 2015, just one year before\\xa0weed was approved to be legalized\\xa0for recreational use in California, Snoop co-founded Los Angeles-based\\xa0Casa Verde Capital\\xa0— a VC fund that has more than doubled in size.Of course, these days, anyone following him on Twitter knows that his attention has been consumed by anything and everything that has to do with Web3 \\u2060— especially NFTs.NFTs are unique digital assets, like artwork and\\xa0sports trading cards, that are verified and stored using blockchain technology, but critics see them as\\xa0overhyped\\xa0and potentially harmful to the environment given the energy-intensive nature of cryptocurrencies. Many NFTs are built on the network behind\\xa0ethereum, the second-biggest token. Earlier this year, Snoop announced his plans to turn Death Row Records, a record label that he acquired from Blackstone-controlled MNRK Music Group, into an \"NFT label.\" Shortly after, one of his first NFT collections called \"Journey of the Dogg\" saw one token sell at auction for over $100,000. In September, Snoop revealed that he had an alias known as anonymous NFT art collector Cozomo de\\' Medici, who had a digital collection worth over $17 million.\"I know [NFTs] have a great opportunity to be big in music, because sooner or later the labels are going to have to come on in,\" Snoop told CNBC in an exclusive interview at last week\\'s NFT.NYC conference in New York City. \"They\\'re going to have to come on home and sit at the table and understand that catalogs and things they hold onto are better served on the blockchain than sitting in the catalog collecting cobwebs.\"\"And it\\'s not just labels,\" his son, Cordell Broadus, a.k.a. Champ Medici, added. \"It\\'s movie studios, it\\'s tech companies, it\\'s beverage companies ... everybody\\'s rushing to Web3 and they see how big Dogg is in the space.\" Snoop has also spent the past year digging into the metaverse.He recently partnered with gaming platform The Sandbox to sell \"The Snoopverse Early\\xa0Access\\xa0Pass\" which gives buyers access to experiences in The Snoopverse, his own branded world within The Sandbox platform. There were 5,000 early access passes minted using blockchain technology at the time of its launch. Each one currently costs a bit more than $600, and according to The Sandbox,\\xa0there are currently 1,114 owners, which means that the sale has generated nearly $700,000 — a significant haircut from the $1.7 million it had generated earlier in the year. The recent downturn has been dubbed by many as the latest \"crypto winter,\" referring to a period when crypto prices fall and stay low for an extended period of time.\"I feel like every great industry has a downfall,\" Snoop said. \"There\\'s been a depression in every industry you can look at ... alcohol, tobacco, clothing, food; every industry you can imagine.\"Some crypto industry leaders expect\\xa0a period of \"creative destruction\"\\xa0wiping out many players. Mark Cuban, who has become a big investor in blockchain-based technologies, recently\\xa0compared the crypto crash\\xa0to \"the lull that the internet went through\" during the dotcom bubble and tweeted that there are too many imitators out there. Snoop Dogg has a similar view.\"This [crypto winter] weeded out all the people who weren\\'t supposed to be in the space and who were abusing the opportunities that were there\" he said. \"Now it\\'s going to bring on great business, and moving forward, when the market comes back, there will only be great things to pick and choose from,\" he added.Snoop\\'s latest project is a collaboration with Food Fighters Universe (FFU), which claims to be the world\\'s first NFT restaurant group. His ice cream brand, Dr. Bombay\\'s Sweet Exploration, is set to open in Los Angeles under the FFU umbrella. The brand was inspired by an NFT that Snoop owns from the prominent Bored Ape Yacht Club collection, many of which skyrocketed in price and became the most recognizable NFTs online, but have seen steep declines in price during the recent digital currencies selloff. ApeCoin, a token launched by Bored Ape creators Yuga Labs, has seen a steep increase since Snoop appeared on-stage at NFT.NYC on Thursday night to debut a new single with Eminem, featuring the Bored Ape branding in the rap duo\\'s corresponding music video.As is the case with many NFT collections, FFU token holders have exclusive access to various festivals, benefits and perks via their ownership of one of the 10,000 NFTs in the collection. Additionally, all physical restaurant locations that fall under the FFU umbrella will accept cryptocurrency as a form of payment.FFU co-founder Kevin Seo told CNBC it will launch \"within this year\" and will be a dessert retail experience built around the Snoop Dogg community. Separately, Champ Medici\\'s Bored Taco will continue to be a food truck and a ghost kitchen brand. \"We\\'re excited to continue to create ways to utilize crypto as payment and showcase utility through our Food Fighters Universe NFTs, with access to events and free food with our NFT holders,\" Seo said.\"Web3 and NFTs? This is just the beginning,\" Champ told CNBC. \"People are going to look back at this five years from now and see how innovative Food Fighters Universe was and how we were pushing the boundaries very early when other people didn\\'t see the vision.\"While prominent investors continue to be believers in the long-term potential of digital assets, including Cathie Wood of Ark Invest, there are plenty of skeptics.Speaking at a\\xa0TechCrunch talk\\xa0on climate change last week, Bill Gates described the crypto and NFT phenomenon as something that\\'s \"100% based on greater fool theory,\" referring to the idea that overvalued assets will go up in price when there are enough investors willing to pay more for them.The billionaire Microsoft co-founder joked that \"expensive digital images of monkeys\" would \"improve the world immensely,\" referring to the much-hyped Bored Apes.Meanwhile, crypto investors continue to grapple with aggressive interest rate hikes from the Federal Reserve and a worsening liquidity crunch that has\\xa0pushed major players into financial difficulty\\xa0and given a megaphone to some of the biggest NFT skeptics. The broader space is also still reeling from the fallout of the\\xa0$60 billion collapse\\xa0of two major tokens last month.']\n",
      "2022-06-28\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "for date in news_dict.keys() & label_dict.keys():\n",
    "    X.append({\"raw\" : news_dict[date], \"date\":date, \"label\":label_dict[date]})\n",
    "print(X[0]['raw'])\n",
    "print(X[0]['date'])\n",
    "print(X[0]['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def add_spaces(text):\n",
    "    # Pattern to match concatenated sentences\n",
    "    pattern = r'(?<!\\d)(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.)(?!\\d)(?!\\w\\.\\w)(?![A-Z][a-z]\\.)'\n",
    "    # Add space after period using the pattern\n",
    "    spaced_text = re.sub(pattern, ' ', text)\n",
    "    return spaced_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "for i, news_group in enumerate(X):\n",
    "    news_group['sentences'] = []\n",
    "    for j, news in enumerate(news_group['raw']):\n",
    "        news_group['sentences'].append(tokenizer.tokenize(add_spaces(news)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "bert = BertModel.from_pretrained('bert-base-cased').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, news_group in enumerate(X):\n",
    "    news_group['sentences_encoding'] = []\n",
    "    for j, sentences in enumerate(news_group['sentences']):\n",
    "        encodings = []\n",
    "        for sentence in sentences:\n",
    "            enc = bert_tokenizer.encode_plus(\n",
    "                  sentence,\n",
    "                  add_special_tokens=True,\n",
    "                  max_length=MAX_LEN,\n",
    "                  return_token_type_ids=False,\n",
    "                  padding='max_length',\n",
    "                  return_tensors='np',\n",
    "                  ).input_ids\n",
    "            emb = bert.forward(torch.from_numpy(enc).to(device)).pooler_output.cpu().detach().numpy()\n",
    "            encodings.append(emb[0])\n",
    "        news_group['sentences_encoding'].append(encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The biggest misunderstanding around cryptocurrencies is that if they\\'re \"not doing a great job of replacing the U. S. dollar, then crypto is failing in its mission,\" Brooks, now the CEO of bitcoin mining and crypto tech company Bitfury Group, told CNBC\\'s Ylan Muii at the Aspen Ideas Festival on Monday.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]['sentences'][1][4] # 2022-01-04의 두번째 뉴스의 다섯번째 문장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.3909702 ,  0.34632587,  0.99769986, -0.9659785 ,  0.74896276,\n",
       "        0.9745248 ,  0.7689903 , -0.99787337, -0.8929932 , -0.09361592,\n",
       "        0.9055611 ,  0.988679  , -0.99946934, -0.99794024,  0.8423971 ,\n",
       "       -0.79562414,  0.92764467, -0.32809824, -0.9992723 , -0.36564717,\n",
       "       -0.75890803, -0.99804544,  0.10416395,  0.98492634,  0.72827303,\n",
       "        0.06069084,  0.919355  ,  0.9995566 ,  0.3971513 , -0.47717744,\n",
       "        0.04779362, -0.9486141 ,  0.91673493, -0.98896897,  0.23323989,\n",
       "        0.5184841 ,  0.8463731 , -0.09684449,  0.6734623 , -0.94865507,\n",
       "       -0.07568976, -0.52607435,  0.718838  , -0.3401398 ,  0.95755965,\n",
       "       -0.15001586, -0.01475518, -0.09948013,  0.07558376,  0.9933939 ,\n",
       "       -0.5712447 , -0.7070382 , -0.9977708 ,  0.5533274 ,  0.9668734 ,\n",
       "        0.12889165,  0.9696663 , -0.0110752 , -0.99971086, -0.46809107,\n",
       "        0.8919303 ,  0.4039762 ,  0.5826248 ,  0.32646158,  0.16087152,\n",
       "       -0.23569421, -0.9433185 ,  0.22570778, -0.24630225,  0.05857337,\n",
       "       -0.0814824 ,  0.12465443,  0.8651274 , -0.70533055, -0.05027961,\n",
       "       -0.72208416, -0.20991084, -0.9981958 ,  0.7703086 ,  0.9992956 ,\n",
       "        0.9238102 , -0.99803895,  0.958992  , -0.1405507 , -0.90626407,\n",
       "        0.931077  , -0.99967283, -0.99537605, -0.03991253,  0.21067429,\n",
       "        0.9414273 , -0.9151976 ,  0.6447661 , -0.93750274,  0.9994891 ,\n",
       "       -0.97893435, -0.06792933,  0.08230178,  0.97636646, -0.9256646 ,\n",
       "       -0.15836297,  0.94727993,  0.99966955, -0.9986071 ,  0.999534  ,\n",
       "        0.7141449 , -0.7877774 , -0.9014909 ,  0.8786113 ,  0.04950545,\n",
       "        0.9092996 , -0.8412093 , -0.89418447, -0.11616106,  0.9656816 ,\n",
       "       -0.8409518 ,  0.9441493 ,  0.61065507, -0.03279079,  0.9996012 ,\n",
       "        0.01484384,  0.9733683 ,  0.9831493 ,  0.8897514 , -0.86856085,\n",
       "        0.00914162, -0.63199663,  0.94852483, -0.78015345,  0.3424648 ,\n",
       "        0.7363521 , -0.9292341 , -0.9990596 ,  0.9945656 , -0.07883461,\n",
       "        0.9994349 , -0.99358463,  0.9959437 , -0.9987332 , -0.93445   ,\n",
       "       -0.89527726, -0.05255901, -0.9932774 , -0.4638769 ,  0.9318671 ,\n",
       "       -0.10416353, -0.9774562 , -0.960606  ,  0.82925904, -0.9549718 ,\n",
       "        0.08892735,  0.41244027, -0.66772527, -0.7149    ,  0.9989701 ,\n",
       "        0.9659833 ,  0.98855066, -0.05274991, -0.9706379 ,  0.88546956,\n",
       "        0.95067275, -0.99601233,  0.9125168 , -0.9972204 ,  0.9881859 ,\n",
       "        0.7924272 ,  0.8356669 , -0.9992675 ,  0.99922454, -0.8855067 ,\n",
       "        0.10550337,  0.43661183,  0.12590246, -0.99964505,  0.3171356 ,\n",
       "        0.37115002,  0.13571337,  0.9844405 , -0.9595698 ,  0.98941517,\n",
       "       -0.85451734,  0.3935486 ,  0.38917866,  0.99962866, -0.97987807,\n",
       "       -0.84244525, -0.945354  , -0.02187839,  0.91870916,  0.67874646,\n",
       "        0.71131384,  0.7864584 ,  0.9996084 , -0.21436684, -0.97241014,\n",
       "       -0.32013318,  0.88620865, -0.1313484 ,  0.9994176 , -0.4967301 ,\n",
       "       -0.9979373 , -0.7843497 ,  0.96311456,  0.9185256 , -0.12015574,\n",
       "        0.9094429 , -0.86002004, -0.3956863 ,  0.9954862 ,  0.77167416,\n",
       "        0.9995703 ,  0.06201348,  0.87442505,  0.4887089 ,  0.92362154,\n",
       "       -0.7608783 , -0.00920811,  0.16209966, -0.83256054,  0.9988191 ,\n",
       "       -0.9960106 ,  0.00185214, -0.01865171, -0.9669022 , -0.9896752 ,\n",
       "        0.87280273,  0.20092253, -0.89136165,  0.00240799,  0.9075667 ,\n",
       "        0.03756449,  0.9563639 ,  0.93798774, -0.71650434, -0.88521755,\n",
       "       -0.9980346 , -0.9991677 , -0.15291658, -0.975257  , -0.19316609,\n",
       "        0.55146253, -0.06442162, -0.67567414, -0.99962294,  0.8213826 ,\n",
       "        0.7079503 , -0.97147363,  0.3391589 , -0.86440635, -0.9994416 ,\n",
       "        0.5067107 , -0.8898169 , -0.9867378 ,  0.9955667 , -0.8566964 ,\n",
       "        0.9983614 ,  0.7756525 , -0.9472424 ,  0.89749444, -0.9996586 ,\n",
       "       -0.22701456,  0.4308094 ,  0.46964738,  0.8199092 , -0.82796913,\n",
       "        0.29506838,  0.9659773 , -0.76416934, -0.88620406,  0.9256908 ,\n",
       "       -0.9985462 ,  0.69211286,  0.01122183,  0.99441653,  0.9033169 ,\n",
       "       -0.41406056,  0.8891527 ,  0.9758779 , -0.95424736, -0.99772215,\n",
       "        0.94156   , -0.84527236, -0.9536688 , -0.04684202,  0.99903244,\n",
       "       -0.9995513 , -0.10334911, -0.82967114, -0.9637033 , -0.9973454 ,\n",
       "        0.3542537 , -0.84916425,  0.32823834,  0.86740863,  0.7352034 ,\n",
       "        0.3383573 ,  0.9798854 ,  0.11432183,  0.4347648 , -0.30877188,\n",
       "       -0.10349592, -0.90957236,  0.761879  ,  0.7994676 ,  0.02804332,\n",
       "       -0.99939966,  0.99825144, -0.96244013, -0.55568737,  0.9845708 ,\n",
       "       -0.9985961 ,  0.5618454 ,  0.22229002, -0.9737171 , -0.19662575,\n",
       "        0.99887943,  0.87375724,  0.08603869, -0.10191568,  0.95960855,\n",
       "       -0.44063008,  0.82237494, -0.9435367 , -0.715739  , -0.05521832,\n",
       "       -0.7704428 ,  0.9951033 ,  0.8748986 , -0.9154379 ,  0.9983637 ,\n",
       "       -0.10826211,  0.15006675, -0.8520714 ,  0.6127988 ,  0.9350925 ,\n",
       "        0.12071256, -0.7236513 , -0.0931217 ,  0.8734468 , -0.9925484 ,\n",
       "       -0.11219081, -0.9984205 , -0.512883  ,  0.92111945,  0.883635  ,\n",
       "       -0.9644239 ,  0.13719434,  0.04255302,  0.9391803 , -0.9993903 ,\n",
       "        0.9997211 , -0.8253    ,  0.01210262,  0.8634089 , -0.93577343,\n",
       "       -0.5954958 ,  0.9450522 ,  0.9951745 ,  0.9811389 , -0.9620973 ,\n",
       "       -0.88672364,  0.43413472,  0.8449887 , -0.9831107 ,  0.03016399,\n",
       "       -0.99986553, -0.9298132 ,  0.9514606 ,  0.9992774 ,  0.17278445,\n",
       "       -0.13718401, -0.99947447,  0.8333512 , -0.9033459 , -0.8769897 ,\n",
       "       -0.07064129, -0.8750023 ,  0.6403766 ,  0.9994571 , -0.63073623,\n",
       "        0.74404454, -0.01472989, -0.88686776,  0.95773363,  0.9006348 ,\n",
       "        0.998748  , -0.882469  ,  0.67095673,  0.91944945, -0.120368  ,\n",
       "       -0.83170485,  0.13530499,  0.9997604 , -0.9099925 ,  0.03700966,\n",
       "       -0.9964535 , -0.07686812, -0.32219186, -0.4063816 , -0.8651461 ,\n",
       "        0.02821244, -0.92222065,  0.9800228 ,  0.662768  ,  0.37913388,\n",
       "       -0.30698776,  0.80661523, -0.75565195,  0.05317601, -0.25181085,\n",
       "       -0.48098925,  0.31524312,  0.32656363,  0.9012939 , -0.71780384,\n",
       "        0.9962448 ,  0.25622278, -0.99947375, -0.9991198 , -0.79843163,\n",
       "       -0.9889871 ,  0.6549405 , -0.64688694,  0.92605346,  0.9676484 ,\n",
       "       -0.9995948 , -0.9997543 , -0.7659281 ,  0.13873129,  0.9047961 ,\n",
       "        0.5756352 ,  0.29859334,  0.46881843, -0.8987173 , -0.07823388,\n",
       "       -0.637596  ,  0.11106095, -0.6022303 , -0.7965974 , -0.9993839 ,\n",
       "        0.84612125, -0.9993542 , -0.91096985,  0.99905187, -0.9989246 ,\n",
       "       -0.9446797 , -0.7620686 , -0.9496038 , -0.5186076 ,  0.18593028,\n",
       "        0.84277415, -0.5617486 , -0.9290525 , -0.98460186,  0.9304258 ,\n",
       "       -0.8613187 ,  0.03700634, -0.9272779 , -0.8160381 ,  0.99552137,\n",
       "        0.96120065, -0.11826374,  0.05910432, -0.9909723 ,  0.9938635 ,\n",
       "       -0.9346331 , -0.9613089 , -0.87733376, -0.04515802, -0.73480815,\n",
       "       -0.99738204, -0.03291554,  0.9990065 ,  0.5163875 ,  0.9533983 ,\n",
       "       -0.1006138 , -0.02850678, -0.8327812 ,  0.12048516, -0.9990748 ,\n",
       "        0.94026744,  0.96601874, -0.8676025 , -0.8407486 ,  0.9715078 ,\n",
       "        0.8593215 , -0.9696955 , -0.98551536,  0.97723824,  0.39545822,\n",
       "        0.7603073 , -0.8447419 , -0.13820574,  0.22637942, -0.00393136,\n",
       "       -0.9458912 , -0.76835585,  0.9868362 , -0.9997752 ,  0.9278874 ,\n",
       "        0.99764323,  0.99962455, -0.2969233 ,  0.4338271 , -0.98791695,\n",
       "        0.3761965 , -0.3668692 ,  0.4568608 , -0.99916875,  0.9976187 ,\n",
       "       -0.9992136 ,  0.75514525, -0.88546026,  0.9007603 ,  0.9627474 ,\n",
       "       -0.47879064, -0.99866325, -0.9976128 ,  0.6553123 ,  0.2199029 ,\n",
       "        0.9253833 ,  0.39057282, -0.06706423, -0.77426946, -0.72175705,\n",
       "        0.9818862 , -0.82080483, -0.8850644 , -0.99960595,  0.99698925,\n",
       "        0.21921556, -0.99092984,  0.9977822 , -0.99350977,  0.94979733,\n",
       "        0.85135967,  0.5750417 ,  0.6936854 , -0.999746  ,  0.99946254,\n",
       "       -0.99764293,  0.73666507, -0.9994141 , -0.9997753 ,  0.9978079 ,\n",
       "       -0.93659806, -0.8275971 , -0.9975643 , -0.999294  ,  0.9424667 ,\n",
       "        0.01058879, -0.30245608,  0.93375677, -0.9985076 , -0.9880577 ,\n",
       "       -0.16804974, -0.9661381 , -0.92733574,  0.9976891 , -0.80816376,\n",
       "        0.9440665 , -0.3952005 ,  0.8106173 ,  0.45109758,  0.9991192 ,\n",
       "       -0.07973569, -0.6978272 , -0.93199563, -0.9678456 ,  0.9225987 ,\n",
       "       -0.867591  ,  0.1865558 ,  0.7486247 ,  0.14342579, -0.77293104,\n",
       "        0.16456269, -0.98505193,  0.66280055,  0.8188922 ,  0.9896428 ,\n",
       "        0.9464225 ,  0.69863266, -0.22664097, -0.6343524 , -0.15294574,\n",
       "       -0.9483477 ,  0.40084818, -0.9948661 ,  0.8397651 , -0.9359512 ,\n",
       "       -0.15001687, -0.2523453 , -0.05081184, -0.7318789 ,  0.99591154,\n",
       "        0.9851561 ,  0.6613431 , -0.1291109 ,  0.9251088 , -0.8824419 ,\n",
       "        0.79806745, -0.9599624 ,  0.13632649,  0.9810329 , -0.288114  ,\n",
       "        0.8793127 , -0.25939202,  0.00908401,  0.9233031 , -0.9738787 ,\n",
       "       -0.9178483 , -0.3232986 ,  0.47746646, -0.46085125, -0.8617345 ,\n",
       "       -0.1542143 ,  0.9935407 , -0.42084804, -0.99793506,  0.98059344,\n",
       "       -0.9943528 , -0.0191161 ,  0.9220904 , -0.2989626 ,  0.9987491 ,\n",
       "       -0.90808594,  0.24439207,  0.19210929, -0.99707425, -0.999804  ,\n",
       "       -0.13629928, -0.05893197, -0.9686096 ,  0.9997876 , -0.45702595,\n",
       "        0.9581557 , -0.99697506,  0.10004331,  0.99870706, -0.02726092,\n",
       "        0.44928327, -0.94889176, -0.5858941 , -0.96572953, -0.28546515,\n",
       "        0.05120825,  0.91927266, -0.9363206 , -0.92956597, -0.9305918 ,\n",
       "        0.99896824, -0.9915924 , -0.6373589 , -0.9056609 ,  0.8564546 ,\n",
       "        0.89484805,  0.31026196,  0.16924064, -0.89773   ,  0.9810452 ,\n",
       "       -0.93731827,  0.9818773 , -0.97250015, -0.97865146,  0.9981043 ,\n",
       "        0.49993235, -0.99772245, -0.01585569, -0.28933582,  0.46886405,\n",
       "        0.2770965 ,  0.89667946, -0.50810146, -0.08741455, -0.6954745 ,\n",
       "        0.8979314 , -0.911112  , -0.9429063 ,  0.04519564, -0.05301667,\n",
       "        0.8140614 ,  0.96649253,  0.91296214,  0.99921596, -0.9974684 ,\n",
       "        0.24849434, -0.02652727,  0.994743  ,  0.01638061, -0.58096194,\n",
       "        0.9374246 ,  0.9949993 , -0.87192714,  0.74508876, -0.23291539,\n",
       "        0.14162567,  0.48032713, -0.2360142 ,  0.9993317 , -0.9610374 ,\n",
       "       -0.15754516, -0.9018909 , -0.9987175 ,  0.99897355,  0.08520537,\n",
       "        0.96577847,  0.220127  ,  0.87327355, -0.18941854,  0.9869764 ,\n",
       "       -0.9864625 , -0.6905974 , -0.9993856 , -0.21945779,  0.6216275 ,\n",
       "       -0.92066765, -0.30949426,  0.9034503 , -0.9958158 , -0.9423751 ,\n",
       "       -0.5416026 , -0.999701  ,  0.8819902 , -0.9943694 , -0.9412267 ,\n",
       "       -0.9181316 ,  0.9993483 ,  0.08825478, -0.93568623,  0.87572306,\n",
       "       -0.7044563 ,  0.9730253 ,  0.94526744, -0.93195003,  0.19779873,\n",
       "       -0.07927807, -0.85057485, -0.9971723 , -0.9596984 , -0.83207977,\n",
       "        0.89208424, -0.91572136, -0.21736318,  0.9805821 ,  0.9237614 ,\n",
       "       -0.9925595 , -0.97322977,  0.9979763 ,  0.2150245 ,  0.9481828 ,\n",
       "        0.08062001, -0.99831706, -0.99914604, -0.04505333,  0.35213473,\n",
       "        0.97211444, -0.24072334, -0.75178695,  0.24265248, -0.28015372,\n",
       "        0.65270466, -0.84897447, -0.43832278, -0.7368635 ,  0.01081701,\n",
       "        0.9995342 , -0.8450885 ,  0.94887084], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]['sentences_encoding'][1][4] # 2022-01-04의 두번째 뉴스의 다섯번째 문장의 bert 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "multihead_attn = nn.MultiheadAttention(EMBED_SIZE, NUM_HEADS).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, news_group in enumerate(X):\n",
    "    news_embeddings = []\n",
    "    for j, sentences_encoding in enumerate(news_group['sentences_encoding']):\n",
    "        query = key = value = torch.tensor(np.array(sentences_encoding)).to(device)\n",
    "        attn_output, attn_output_weights = multihead_attn(query, key, value)\n",
    "        news_embeddings.append(attn_output.mean(dim=0).cpu().detach().numpy())\n",
    "    news_group['news_embeddings'] = news_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, news_group in enumerate(X):\n",
    "    query = key = value = torch.tensor(np.array(news_group['news_embeddings'])).to(device)\n",
    "    attn_output, attn_output_weights = multihead_attn(query, key, value)\n",
    "    news_group['date_embedding'] = attn_output.mean(dim=0).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.05694321e-02, -2.32308254e-01, -2.43725963e-02,  1.56033680e-01,\n",
       "        4.13340777e-02, -1.40239492e-01, -3.07808127e-02,  7.52342632e-03,\n",
       "       -1.46271348e-01,  8.12880024e-02,  1.52813476e-02,  5.48344105e-03,\n",
       "        6.98007047e-02,  1.84107460e-02,  6.54059201e-02, -1.50618717e-01,\n",
       "       -1.68354139e-01, -3.90793160e-02, -1.42386436e-01, -2.94691324e-01,\n",
       "       -2.17363402e-01, -1.01280391e-01,  1.24899499e-01, -3.91151197e-02,\n",
       "        6.43899143e-02,  1.16752379e-01,  6.59342259e-02,  2.05204293e-01,\n",
       "        9.58002210e-02, -1.04738317e-01,  1.32651813e-03,  2.33170204e-02,\n",
       "       -9.43399295e-02,  4.86717671e-02, -6.75244629e-02,  1.21288337e-02,\n",
       "        2.97673233e-03, -5.37108909e-03,  7.62194842e-02, -4.66395169e-04,\n",
       "        9.15888697e-02, -9.22254287e-03, -1.99614584e-01,  5.62423393e-02,\n",
       "        1.64805457e-01,  1.57257944e-01, -3.27078663e-02,  9.16227102e-02,\n",
       "        2.16402516e-01, -2.27462262e-01,  1.31599292e-01,  3.06630414e-02,\n",
       "       -3.85431349e-02,  1.67334646e-01, -3.93796712e-02,  5.00717983e-02,\n",
       "       -4.75110561e-02, -6.84798136e-03, -1.41796634e-01, -1.35222241e-01,\n",
       "       -4.78570759e-02, -4.94722426e-02,  4.64308187e-02, -1.29734010e-01,\n",
       "       -2.33180746e-01,  1.98657066e-02, -1.27210724e-03,  4.95041423e-02,\n",
       "       -6.28133565e-02,  1.57232910e-01,  4.10829782e-02,  7.05836341e-02,\n",
       "       -1.21656477e-01, -2.26449817e-01,  4.29760627e-02,  1.16096720e-01,\n",
       "       -6.01044819e-02, -4.55077291e-02, -5.85651360e-02, -9.92031186e-04,\n",
       "        2.36525387e-01, -1.93769857e-01, -1.93704993e-01, -5.40245231e-03,\n",
       "       -8.47971886e-02, -3.75088751e-02, -2.16559917e-02, -5.36596403e-02,\n",
       "        1.01250164e-01, -1.62097942e-02, -9.34845433e-02,  1.41192600e-01,\n",
       "        1.73636153e-02,  8.55841637e-02,  1.12088934e-01, -5.83647564e-02,\n",
       "       -3.93668003e-03,  6.85188696e-02, -1.65842593e-01,  1.18390163e-02,\n",
       "       -2.03585289e-02,  1.12400763e-01,  1.48368962e-02, -2.63294160e-01,\n",
       "        6.63968325e-02, -9.84260812e-03,  1.73703395e-02, -7.14970827e-02,\n",
       "        3.31666023e-02,  1.95172243e-02, -2.83108085e-01, -3.12830210e-01,\n",
       "        4.39095311e-02, -1.56877816e-01,  5.05374745e-02,  1.08648002e-01,\n",
       "        5.38989082e-02,  7.90459216e-02,  3.57032456e-02,  3.14716920e-02,\n",
       "        3.96656767e-02, -5.14284745e-02,  1.70305848e-01, -2.24415541e-01,\n",
       "        6.90915138e-02,  8.01484436e-02, -1.77424457e-02,  1.24408171e-01,\n",
       "       -3.67489532e-02,  1.80927739e-01, -3.90824527e-02, -1.67324662e-01,\n",
       "        2.81388909e-02, -4.26716134e-02, -9.95408818e-02,  5.96792363e-02,\n",
       "        4.54940572e-02, -1.27496064e-01,  3.96922678e-02, -2.20526665e-01,\n",
       "        5.34805916e-02,  7.66977370e-02, -5.67502901e-02,  1.30987570e-01,\n",
       "       -1.46473825e-01, -1.27249688e-01, -9.14979503e-02,  1.26019776e-01,\n",
       "        4.06821370e-02, -7.44548291e-02, -2.40833052e-02, -3.56893800e-02,\n",
       "        1.38872057e-01, -1.42018527e-01,  1.52638499e-02, -2.28575081e-01,\n",
       "       -5.07844910e-02, -1.86264992e-01, -2.35882401e-02,  6.83455076e-03,\n",
       "       -3.23796421e-02, -1.72880799e-01,  5.46462834e-02, -1.29748806e-02,\n",
       "       -3.99801647e-03, -1.05378352e-01,  7.23803882e-03, -1.75148377e-03,\n",
       "        4.13959697e-02,  1.11640982e-01, -2.48731658e-01,  3.89388762e-02,\n",
       "        6.36424199e-02, -9.22983512e-02,  1.26163125e-01,  1.19923323e-01,\n",
       "        2.36197621e-01,  1.68297634e-01,  2.28016227e-01, -8.19376335e-02,\n",
       "        6.03411347e-02,  3.11454944e-02, -8.55233297e-02, -1.46350548e-01,\n",
       "        3.80074373e-03, -6.28612339e-02,  1.66776270e-01,  9.58773792e-02,\n",
       "       -1.85530350e-01,  1.91743061e-01,  1.09718680e-01, -3.58680151e-02,\n",
       "       -2.41708569e-02,  9.81453713e-03,  2.04826947e-02,  5.68123087e-02,\n",
       "        2.78013609e-02, -7.99029320e-02,  3.21715437e-02, -1.76433548e-02,\n",
       "        3.86303179e-02, -5.21325581e-02, -1.56145722e-01, -3.16119194e-02,\n",
       "        6.33091033e-02, -7.76701048e-02,  7.32445568e-02,  7.91724026e-02,\n",
       "        1.83893237e-02,  8.35277438e-02, -3.11328825e-02,  1.84325784e-01,\n",
       "       -2.54382398e-02,  6.83537393e-04, -1.53169543e-01,  1.05359286e-01,\n",
       "        1.45092875e-01,  1.99809372e-01, -1.03473857e-01,  1.27604961e-01,\n",
       "        2.33357474e-01,  1.00764774e-01,  1.49410725e-01, -4.81923576e-03,\n",
       "       -5.67004345e-02,  4.72014807e-02,  7.56504387e-02, -8.43939744e-03,\n",
       "       -3.48428898e-02,  1.58608422e-01, -7.53308460e-02,  6.91673309e-02,\n",
       "       -2.32977830e-02,  5.46084857e-03,  1.38224304e-01, -1.20187268e-01,\n",
       "       -9.50606465e-02, -2.19241884e-02,  1.51805840e-02,  1.27504468e-01,\n",
       "       -9.30560976e-02,  1.49116144e-01, -1.21966135e-02, -2.55258735e-02,\n",
       "       -1.16768286e-01,  1.51742875e-04, -7.45340288e-02, -2.39914767e-02,\n",
       "       -1.53308243e-01, -1.42475456e-01, -7.46507347e-02, -4.37067896e-02,\n",
       "       -5.68739846e-02,  8.92054439e-02,  1.04519501e-01,  1.37124151e-01,\n",
       "        3.46086100e-02,  7.68721253e-02, -1.93602890e-01,  1.14393234e-01,\n",
       "       -1.76171347e-01,  4.71566729e-02, -5.94354048e-03, -1.66707084e-01,\n",
       "       -1.22252107e-01, -1.74664944e-01,  1.66927099e-01,  1.23542480e-01,\n",
       "        5.92311472e-02, -7.94276148e-02,  7.49707734e-03,  1.05408800e-03,\n",
       "        8.77876729e-02, -1.27331465e-01,  1.50949448e-01, -6.04844093e-02,\n",
       "        1.35295153e-01, -2.48430729e-01,  1.54919237e-01,  1.59962997e-01,\n",
       "       -2.30047219e-02, -6.38115257e-02,  6.38433918e-02, -1.03573143e-01,\n",
       "       -4.61869165e-02, -1.18990108e-01, -1.34641929e-02,  1.11482292e-03,\n",
       "        1.28439307e-01,  5.87683842e-02, -9.56438184e-02, -3.38578783e-02,\n",
       "       -1.30577952e-01, -1.67655095e-01, -1.87006388e-02,  6.31913990e-02,\n",
       "       -1.54739916e-01,  9.04546008e-02, -9.65120792e-02, -2.26411581e-01,\n",
       "        9.68412161e-02,  1.86378956e-02,  1.72657594e-01,  1.06549174e-01,\n",
       "        1.39645427e-01, -1.23008236e-01,  1.13570346e-02,  3.30861956e-01,\n",
       "        1.40007650e-02, -1.98404670e-01,  1.74124479e-01,  1.91804752e-01,\n",
       "        2.49758288e-02,  1.56197086e-01, -4.45818296e-03,  1.75525427e-01,\n",
       "        9.77656692e-02, -1.33392602e-01, -2.03027502e-02, -3.29147242e-02,\n",
       "       -1.54358923e-01, -3.65904979e-02, -1.81723356e-01, -7.69961476e-02,\n",
       "       -1.70790359e-01, -2.08029807e-01, -6.77294135e-02,  2.84568127e-02,\n",
       "       -2.13877320e-01,  4.33565080e-02,  8.74692425e-02,  3.59877236e-02,\n",
       "       -1.31980166e-01, -8.29178169e-02,  7.22176805e-02, -1.70418620e-01,\n",
       "        3.29413936e-02,  1.19620815e-01,  1.49707720e-02,  2.41643548e-01,\n",
       "       -3.52663994e-02,  2.36638829e-01,  1.10639080e-01, -7.90615231e-02,\n",
       "       -8.22584182e-02, -8.81327242e-02,  1.92189127e-01, -1.08045757e-01,\n",
       "       -7.24951364e-03, -8.49360675e-02, -1.38411939e-01, -7.86042064e-02,\n",
       "       -1.20005012e-01,  5.98553866e-02, -7.73907825e-02, -2.18615793e-02,\n",
       "        2.84190774e-01,  7.13778939e-03, -1.35266874e-02,  8.00857670e-04,\n",
       "       -4.80104536e-02,  1.41898453e-01,  1.27609521e-01,  1.21981069e-01,\n",
       "       -1.54364258e-01, -1.59474999e-01,  1.69492185e-01, -2.89537143e-02,\n",
       "       -1.05503023e-01,  2.30338871e-02, -1.64005831e-01, -7.81678632e-02,\n",
       "       -4.20816690e-02,  5.14575355e-02, -8.91900659e-02,  6.59131110e-02,\n",
       "       -3.69852006e-01,  2.49091849e-01,  9.51176509e-02, -1.95285268e-02,\n",
       "       -1.35336831e-01, -1.43887326e-01, -1.48424983e-01, -4.54137921e-02,\n",
       "       -4.10419367e-02, -1.50364889e-02, -2.29219601e-01,  1.61770880e-01,\n",
       "        3.23454849e-02,  1.62205517e-01, -1.20147225e-02,  2.05672011e-01,\n",
       "       -1.90003626e-02, -1.29003644e-01, -8.17398652e-02,  1.14606105e-01,\n",
       "       -9.83885452e-02, -3.43545042e-02,  7.60021713e-03,  8.75587612e-02,\n",
       "        9.87733230e-02,  1.16058663e-01, -2.73220465e-02,  1.75379559e-01,\n",
       "        5.86911365e-02, -1.29936084e-01,  1.83044061e-01, -4.08593863e-02,\n",
       "        1.89709485e-01, -1.38242051e-01, -5.98418415e-02, -6.54421374e-02,\n",
       "        7.80902505e-02, -1.38219176e-02, -1.14274174e-01, -1.21304803e-01,\n",
       "        5.14355600e-02,  1.48802981e-01,  4.35485095e-02, -6.83778524e-02,\n",
       "       -1.02613531e-01, -3.11936326e-02,  3.77774751e-03,  9.03444290e-02,\n",
       "        7.61388689e-02,  1.71733662e-01,  1.22845128e-01, -1.26348540e-01,\n",
       "       -5.45815490e-02, -1.09627694e-01,  7.78606832e-02, -2.31035620e-01,\n",
       "       -8.71534795e-02,  1.25789344e-01, -2.16958031e-01, -2.99297627e-02,\n",
       "       -8.33089352e-02, -1.79638833e-01, -3.17669436e-02, -4.40357141e-02,\n",
       "        3.56154889e-02,  1.13896936e-01,  1.06416486e-01, -6.96050823e-02,\n",
       "        1.89988986e-02, -1.29805673e-02,  4.45308536e-02,  8.86424184e-02,\n",
       "       -1.50645122e-01, -7.25567788e-02,  1.08732641e-01, -7.09885359e-02,\n",
       "        1.04612470e-01,  1.99303910e-01,  5.38910590e-02,  7.48831779e-02,\n",
       "       -9.24794972e-02, -8.72950181e-02,  1.08571602e-02,  5.37405908e-02,\n",
       "        3.80182676e-02,  1.35558769e-02, -1.02478415e-02,  2.18250379e-01,\n",
       "       -1.04981445e-01,  7.14806467e-02,  3.92158777e-02,  9.15191397e-02,\n",
       "        8.66876170e-02, -1.20124362e-01, -3.61436270e-02, -2.17238516e-01,\n",
       "       -1.20252267e-01, -8.02585334e-02,  3.64769958e-02, -1.63705632e-01,\n",
       "        8.79051387e-02, -6.80618212e-02, -6.49383813e-02, -1.69474687e-02,\n",
       "       -6.76191002e-02, -1.92162082e-01,  9.91553217e-02,  8.45525786e-02,\n",
       "       -1.95852026e-01, -7.71167204e-02, -9.29999650e-02, -1.25847593e-01,\n",
       "       -9.11022536e-03,  1.14000246e-01, -9.41472277e-02,  1.79496664e-03,\n",
       "        2.25940704e-01, -1.41878664e-01,  7.63388127e-02,  8.05036053e-02,\n",
       "        2.20607698e-01, -5.90790920e-02,  6.05585724e-02, -1.55360429e-02,\n",
       "       -7.94427022e-02,  1.95662510e-02,  7.93799013e-03,  1.59119710e-01,\n",
       "        2.51238346e-01,  4.60477099e-02,  4.81891260e-02,  1.71169639e-03,\n",
       "       -6.28046831e-03, -2.32077986e-02,  3.43884528e-02, -7.38072246e-02,\n",
       "       -1.21050023e-01, -1.86581105e-01, -1.03519641e-01,  3.80641362e-03,\n",
       "       -1.93019837e-01, -5.26908748e-02,  1.74755696e-02,  3.87511179e-02,\n",
       "       -3.38478237e-02,  5.59121668e-02, -1.40323818e-01,  8.62909183e-02,\n",
       "        6.69916868e-02,  7.13911802e-02,  1.21455692e-01, -1.29471079e-01,\n",
       "       -6.41993582e-02,  1.20193824e-01, -3.69860046e-02, -8.10769200e-02,\n",
       "        1.06814831e-01,  9.52628702e-02,  3.37968022e-02,  2.08709404e-01,\n",
       "       -6.85864240e-02, -2.11491212e-02,  2.50522614e-01, -1.15299240e-01,\n",
       "       -2.02416442e-02,  4.46586218e-03, -4.15520407e-02, -6.02898821e-02,\n",
       "       -7.24401278e-03,  1.94491625e-01, -2.75942802e-01, -3.60636972e-02,\n",
       "        7.87717402e-02, -1.73065782e-01, -2.53123879e-01, -8.93022865e-03,\n",
       "       -3.89052778e-02,  5.14258370e-02,  1.12888932e-01, -2.48201638e-02,\n",
       "        7.57373422e-02,  5.35731465e-02, -6.43478855e-02,  2.47779295e-01,\n",
       "        7.96662197e-02, -1.70216799e-01,  1.13989329e-02, -2.15899393e-01,\n",
       "        8.61858949e-02, -8.47874880e-02,  2.42789194e-01,  8.13582167e-02,\n",
       "        3.85558568e-02, -1.90214977e-01,  1.62940174e-01, -3.44433449e-02,\n",
       "       -7.73946643e-02, -2.50414968e-01,  4.81817387e-02, -1.15267172e-01,\n",
       "        7.28417933e-02, -1.65368363e-01,  1.68099981e-02,  4.03087437e-02,\n",
       "        3.48864168e-01, -8.57793912e-02,  1.69139564e-01, -7.85352960e-02,\n",
       "       -5.38355298e-03,  1.47150159e-01,  1.34928048e-01,  1.40355110e-01,\n",
       "       -8.91478285e-02,  2.06719786e-01,  4.82741594e-02,  1.16296135e-01,\n",
       "       -1.90637529e-01,  8.22077617e-02, -4.24055867e-02,  4.60640043e-02,\n",
       "       -1.84932888e-01, -7.83901513e-02,  5.10218963e-02,  4.01862115e-02,\n",
       "       -8.57599080e-02, -2.33280659e-02,  9.51507911e-02, -2.24620804e-01,\n",
       "        1.61548525e-01,  9.72110480e-02,  4.62111011e-02,  1.31380722e-01,\n",
       "        6.56634420e-02,  3.81199643e-02,  1.14019394e-01, -4.53962088e-02,\n",
       "        1.66084953e-02, -1.49937630e-01, -1.16798565e-01,  2.80085534e-01,\n",
       "       -1.98588252e-01,  9.76398587e-04, -2.27580648e-02,  2.54535656e-02,\n",
       "        6.34635463e-02,  2.14864224e-01, -5.32865971e-02,  1.65663306e-02,\n",
       "        1.45426601e-01, -1.63838312e-01,  2.36465014e-03, -1.90565988e-01,\n",
       "        5.25047770e-03, -6.18259236e-02,  7.16463923e-02,  7.71799833e-02,\n",
       "        1.83454975e-02,  1.07443959e-01, -1.16524491e-02,  3.06378491e-02,\n",
       "        1.02404080e-01,  3.11212502e-02,  7.56153837e-02, -1.11439735e-01,\n",
       "       -2.46599048e-01,  4.00335621e-03,  7.02047860e-03,  1.48610279e-01,\n",
       "        1.00584373e-01,  1.71513081e-01,  6.91395476e-02,  3.03656101e-01,\n",
       "        6.27387241e-02,  2.80563291e-02, -2.40910873e-02,  5.55537008e-02,\n",
       "        1.62331741e-02, -2.28847712e-01, -1.56951591e-01, -1.45258037e-02,\n",
       "       -3.82810012e-02,  5.23111299e-02,  1.21802732e-01, -1.19648665e-01,\n",
       "        1.11956075e-01, -1.91271007e-01,  3.69569287e-03, -2.10610293e-02,\n",
       "        1.23494528e-01, -5.85888848e-02,  8.80395100e-02, -6.92749172e-02,\n",
       "       -3.72352898e-02, -1.65161081e-02, -3.68237197e-02,  3.89681458e-02,\n",
       "        7.49637410e-02, -1.27409071e-01, -1.63010895e-01,  1.57911479e-01,\n",
       "        2.86978334e-02, -6.32617325e-02, -9.32477713e-02, -1.30000904e-01,\n",
       "       -6.24167174e-02,  1.59418374e-01, -9.43855047e-02, -8.17729160e-03,\n",
       "        1.89968944e-02,  3.33036557e-02,  4.16760799e-03,  1.26167208e-01,\n",
       "        1.01903901e-01,  1.66280456e-02,  2.02816650e-02,  5.26971929e-02,\n",
       "       -1.19563788e-01, -2.68653966e-02,  1.30766854e-01,  2.09759355e-01,\n",
       "        7.00795650e-02,  5.55054098e-02,  6.76307529e-02, -9.72722322e-02,\n",
       "       -2.81974338e-02, -1.05797112e-01,  1.17097422e-01,  1.23786293e-01,\n",
       "        1.65279396e-02,  1.01018719e-01, -8.17071050e-02,  2.52527118e-01,\n",
       "       -1.85178965e-01, -7.23122358e-02,  6.93244934e-02,  2.33814090e-01,\n",
       "        5.63941151e-02, -5.55566326e-02, -5.64438552e-02, -1.23295352e-01,\n",
       "        8.36294517e-02, -1.24104820e-01,  2.97970057e-01, -1.24309927e-01,\n",
       "        2.05115795e-01, -1.03299759e-01, -4.95966189e-02, -7.92748481e-02,\n",
       "       -1.53516158e-01,  1.91891283e-01,  1.57361910e-01, -7.73021877e-02,\n",
       "       -7.87657034e-03,  8.76593515e-02, -1.42888278e-01,  8.81591365e-02,\n",
       "        1.27309546e-01,  1.75190374e-01,  4.86077964e-02, -1.77104980e-01,\n",
       "        3.88428271e-02, -5.63125759e-02,  2.42598265e-01, -5.25044426e-02,\n",
       "        8.46359357e-02,  2.47665867e-01, -1.23021387e-01,  1.98987216e-01,\n",
       "        6.01771772e-02, -5.11360704e-04,  1.43066674e-01, -1.15760565e-01,\n",
       "       -2.88043972e-02,  3.77737731e-02, -1.07596233e-01, -6.45451918e-02,\n",
       "       -1.34135885e-02, -6.84319437e-02,  6.75434768e-02, -4.27568778e-02,\n",
       "        2.16528140e-02,  2.34562792e-02,  1.37830675e-01,  1.29013285e-01,\n",
       "       -1.93907142e-01, -1.00937292e-01, -1.35392413e-01, -2.18368098e-01,\n",
       "       -2.91107427e-02,  1.59423098e-01,  1.37484208e-01,  2.35068947e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]['date_embedding'] # 2022-01-04의 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data.pkl', 'wb') as f:\n",
    "    pickle.dump(X, f)\n",
    "\n",
    "# with open('data.pkl', 'rb') as f:\n",
    "#     X = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        date_emb = torch.from_numpy(self.data[idx][\"date_embedding\"])\n",
    "        label = torch.tensor(self.data[idx][\"label\"])\n",
    "        return date_emb, label\n",
    "\n",
    "class FFN(nn.Module):\n",
    "  def __init__(self, input_size, n_classes, dropout=0.5):\n",
    "    super(FFN, self).__init__()\n",
    "    self.layers = nn.Sequential(\n",
    "        nn.Linear(input_size, 256),\n",
    "        nn.BatchNorm1d(256),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=dropout),\n",
    "        nn.Linear(256, n_classes),\n",
    "    )\n",
    "  def forward(self, _input):\n",
    "    return self.layers(_input)\n",
    "  \n",
    "def create_data_loader(dataset):\n",
    "  return DataLoader(\n",
    "            dataset,\n",
    "            batch_size=BATCH,\n",
    "            num_workers=2\n",
    "        )\n",
    "\n",
    "def train_epoch1(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
    "  model.train()\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "  for batch in tqdm(data_loader):\n",
    "    data, targets = batch\n",
    "    data, targets = data.to(device), targets.to(device)\n",
    "    outputs = model(data)\n",
    "    preds = torch.argmax(outputs, dim=1)\n",
    "    loss = loss_fn(outputs, targets)\n",
    "    correct_predictions += torch.sum(preds == targets)\n",
    "    losses.append(loss.item())\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "def eval_model1(model, data_loader, loss_fn, device, n_examples):\n",
    "  model.eval()\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "  with torch.no_grad():\n",
    "    for batch in tqdm(data_loader):\n",
    "      data, targets = batch\n",
    "      data, targets = data.to(device), targets.to(device)\n",
    "      outputs = model(data)\n",
    "      preds = torch.argmax(outputs, dim=1)\n",
    "      loss = loss_fn(outputs, targets)\n",
    "      correct_predictions += torch.sum(preds == targets)\n",
    "      losses.append(loss.item())\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(len(X) * 0.9)\n",
    "train_data, test_data = X[:split], X[split:]\n",
    "train_data_loader = create_data_loader(NewsDataset(train_data))\n",
    "test_data_loader = create_data_loader(NewsDataset(test_data))\n",
    "model = FFN(EMBED_SIZE, 2).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR_RATE)\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "  optimizer,\n",
    "  num_warmup_steps=0,\n",
    "  num_training_steps=total_steps\n",
    ")\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "os.makedirs('./checkpoint', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Training Start\n",
      "Epoch 1/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:00<00:00, 83.55it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.7026787256372387 accuracy 0.5132743362831859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 15.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss 0.6896548122167587 accuracy 0.6153846153846154\n",
      "Epoch 2/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:00<00:00, 82.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6594347933243061 accuracy 0.6194690265486725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 15.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss 0.6736018359661102 accuracy 0.7307692307692308\n",
      "Epoch 3/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:00<00:00, 83.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6551731537128317 accuracy 0.5929203539823009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 15.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss 0.6270120292901993 accuracy 0.6923076923076923\n",
      "Epoch 4/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:00<00:00, 84.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6466768106509899 accuracy 0.6194690265486725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 13.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss 0.5640236958861351 accuracy 0.6923076923076923\n",
      "Epoch 5/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:00<00:00, 84.19it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6391134981451363 accuracy 0.6725663716814159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 15.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss 0.5587659478187561 accuracy 0.6538461538461539\n",
      "Epoch 6/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:00<00:00, 80.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6395824130239158 accuracy 0.6504424778761062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 14.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss 0.6168186441063881 accuracy 0.6153846153846154\n",
      "Epoch 7/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:00<00:00, 77.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.623635222171915 accuracy 0.6637168141592921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 14.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss 0.6335851550102234 accuracy 0.576923076923077\n",
      "Epoch 8/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:00<00:00, 81.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6249129936612886 accuracy 0.6858407079646017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 15.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss 0.6614764928817749 accuracy 0.5384615384615385\n",
      "Epoch 9/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:00<00:00, 86.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6150502963312741 accuracy 0.6769911504424778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 14.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss 0.6973901987075806 accuracy 0.42307692307692313\n",
      "Epoch 10/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:00<00:00, 82.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6130277483627714 accuracy 0.6946902654867256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 15.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss 0.7396221831440926 accuracy 0.42307692307692313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_accuracy = 0\n",
    "print(\">> Training Start\")\n",
    "for epoch in range(EPOCHS):\n",
    "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "  print('-' * 10)\n",
    "  train_acc, train_loss = train_epoch1(model, train_data_loader, loss_fn, optimizer, device, scheduler, len(train_data))\n",
    "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "  val_acc, val_loss = eval_model1(model, test_data_loader, loss_fn, device, len(test_data))\n",
    "  print(f'Val loss {val_loss} accuracy {val_acc}')\n",
    "  if best_accuracy < val_acc:\n",
    "    best_accuracy = val_acc\n",
    "    check = {\n",
    "        'state_dict': model.state_dict(),\n",
    "    }\n",
    "    \n",
    "    torch.save(check, f\"./checkpoint/{epoch}.ckpt\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}